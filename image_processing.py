# -*- coding: utf-8 -*-
"""image_processing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Oh2qJpouuJ199Ag8kuUQ75ldmonBHWq7

--------------------------------------------------------
# SmartCoach - Image Sequence Emotion Analysis
Processes individual player images to detect emotional states using a pretrained ResNet18 model.

--------------------------------------------------------
"""

import torch
from torchvision import models, transforms
from PIL import Image
import os
import json

"""# Step 1: Load the pretrained emotion classification model
 --------------------------------------------------------
 Loads a fine-tuned ResNet18 model trained on emotion-labeled images, ready for inference.

"""

# Load trained model
model = models.resnet18(weights=None)
model.fc = torch.nn.Linear(model.fc.in_features, 8)
model.load_state_dict(torch.load("/content/emotion_model.pth", map_location=torch.device('cpu')))
model.eval() # Set model to inference mode

"""# Step 2: Define image preprocessing pipeline
--------------------------------------------------------
Applies the same normalization and resizing used during training to maintain prediction consistency.
"""

transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize image to match ResNet input
    transforms.ToTensor(),          # Convert image to PyTorch tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Standardize to ImageNet stats
                         std=[0.229, 0.224, 0.225])
])

"""# Step 3: Prepare folder structure for incoming images
 --------------------------------------------------------
 Ensures the target directory exists to store uploaded image files before processing.
"""

image_folder = "Write the path here"
os.makedirs(image_folder, exist_ok=True)

results = []
emotion_map = ['Anger', 'Focus', 'Frustration', 'Happiness', 'Neutral', 'Stress', 'Surprise', 'Unclear']

"""# Step 4: Loop through each image and predict emotions
 --------------------------------------------------------
For each valid image, we apply preprocessing, perform inference, and map the prediction to an emotion class.
"""

for idx, filename in enumerate(sorted(os.listdir(image_folder))):
    if filename.lower().endswith(('jpg', 'jpeg', 'png')):
        path = os.path.join(image_folder, filename)               # Build full image path
        image = Image.open(path).convert("RGB")                   # Load and convert to RGB
        input_tensor = transform(image).unsqueeze(0)              # Apply transforms and add batch dim

        with torch.no_grad():                                     # Disable gradient tracking
            output = model(input_tensor)                          # Forward pass through the model
            pred = torch.argmax(output, dim=1).item()             # Get predicted class index
            results.append({"time": f"img{idx+1}",                # Store image index as timestamp
                            "emotion": emotion_map[pred]})        # Map class index to emotion label

"""# Step 5: Save the analysis results in JSON format
--------------------------------------------------------
 The results are stored in a structured JSON file to be reused by front-end or report generation tools.
"""

with open("emotions.json", "w") as f:
    json.dump(results, f, indent=2)

print("âœ… Image emotion analysis complete. Results saved to 'emotions.json'")

